mist.py:

from ctransformers import AutoModelForCausalLM, AutoConfig, Config
conf = AutoConfig(Config(temperature=0.8, repetition_penalty=1.1,
                         batch_size=52, max_new_tokens=1024,
                         context_length=2048))
llm = AutoModelForCausalLM.from_pretrained("mistral-7b-instruct-v0.1.Q4_K_M.gguf",
        model_type="mistral", config = conf)
yourprompt = str(input("promt"))
while(yourprompt!="exit"):
    mistral_prompt = f"<s>[INST] {yourprompt} [/INST]"
    answer = llm(mistral_prompt, temperature = 0.7,
             repetition_penalty = 1.15,
             max_new_tokens = 2048)
    print(answer)
    yourprompt = str(input("promt"))